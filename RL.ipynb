{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5627c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "# ===============================\n",
    "# GAME CELL with Progressive Difficulty\n",
    "# ===============================\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class TrainGameEnv:\n",
    "    def __init__(self, initial_capacity=100, seed=None, verbose=False):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "        # train\n",
    "        self.initial_capacity = initial_capacity\n",
    "        self.capacity = initial_capacity\n",
    "        self.passengers_onboard = 0\n",
    "\n",
    "        # scoring trackers\n",
    "        self.raw_score = 0.0\n",
    "        self.total_boarded = 0\n",
    "        self.total_unused = 0.0\n",
    "        self.total_config_cost = 0.0\n",
    "\n",
    "        # stations\n",
    "        self.stations = [\n",
    "            \"Recto\", \"Legarda\", \"Pureza\", \"V. Mapa\", \"J. Ruiz\", \"Gilmore\",\n",
    "            \"Betty Go\", \"Cubao\", \"Anonas\", \"Katipunan\",\n",
    "            \"Santolan\", \"Marikina\", \"Antipolo\"\n",
    "        ]\n",
    "        self.num_stations = len(self.stations)\n",
    "        self.station_idx = 0\n",
    "        self.direction = +1\n",
    "\n",
    "        # collapse mechanic\n",
    "        self.weight_window = []\n",
    "        self.window_size = 10\n",
    "        self.collapse_threshold = 10.0  # will shrink with time (soft pressure)\n",
    "\n",
    "        # time simulation\n",
    "        self.sim_hour = random.randint(0,23)\n",
    "        self.steps = 0\n",
    "        self.max_steps = 2000\n",
    "\n",
    "        # bookkeeping\n",
    "        self.station_visits = 0\n",
    "        self.history = []\n",
    "        self.done = False\n",
    "        self.done_reason = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _time_multiplier(self, hour):\n",
    "        if 6 <= hour <= 8:\n",
    "            return 1.9\n",
    "        if 11 <= hour <= 13:\n",
    "            return 1.6\n",
    "        if 17 <= hour <= 19:\n",
    "            return 1.9\n",
    "        return 0.8 if random.random() < 0.45 else 1.0\n",
    "\n",
    "    def _arrival_bounds(self, idx):\n",
    "        if idx in (0, self.num_stations-1, 7):\n",
    "            return (40, 150)\n",
    "        return (10, 70)\n",
    "\n",
    "    def _simulate_arrivals(self):\n",
    "        amin, amax = self._arrival_bounds(self.station_idx)\n",
    "        base = random.randint(amin, amax)\n",
    "        mult = self._time_multiplier(self.sim_hour)\n",
    "\n",
    "        # === Passenger Surge Scaling ===\n",
    "        surge_factor = 1.0 + (self.steps / 2000) * 2.0  # grows up to 3x\n",
    "        return max(0, int(round(base * mult * surge_factor)))\n",
    "\n",
    "    def reset(self):\n",
    "        self.capacity = self.initial_capacity\n",
    "        self.passengers_onboard = 0\n",
    "        self.raw_score = 0.0\n",
    "        self.total_boarded = 0\n",
    "        self.total_unused = 0.0\n",
    "        self.total_config_cost = 0.0\n",
    "        self.station_idx = 0\n",
    "        self.direction = +1\n",
    "        self.weight_window = []\n",
    "        self.collapse_threshold = 10.0\n",
    "        self.sim_hour = random.randint(0,23)\n",
    "        self.steps = 0\n",
    "        self.station_visits = 0\n",
    "        self.history = []\n",
    "        self.done = False\n",
    "        self.done_reason = None\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        return np.array([\n",
    "            float(self.capacity),\n",
    "            float(self.passengers_onboard),\n",
    "            float(self.station_idx),\n",
    "            float(self.direction),\n",
    "            float(self.sim_hour)\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    # ---------- main step ----------\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            raise RuntimeError(\"Environment is done. Call reset().\")\n",
    "\n",
    "        # action effects\n",
    "        if action == 0:\n",
    "            self.capacity += 100\n",
    "            cost = 10.0\n",
    "            weight = 1.0\n",
    "        elif action == 1:\n",
    "            self.capacity += 50\n",
    "            cost = 5.0\n",
    "            weight = 0.5\n",
    "        else:\n",
    "            cost = 0.0\n",
    "            weight = 0.0\n",
    "\n",
    "        config_penalty = 0.5 * cost\n",
    "        self.total_config_cost += cost\n",
    "        self.raw_score -= config_penalty\n",
    "\n",
    "        # collapse check\n",
    "        self.weight_window.append(weight)\n",
    "        if len(self.weight_window) > self.window_size:\n",
    "            self.weight_window.pop(0)\n",
    "        window_sum = sum(self.weight_window)\n",
    "\n",
    "        # === Soft Collapse Pressure ===\n",
    "        self.collapse_threshold = max(3.0, 10.0 - (self.steps / 200))  # shrinks over time\n",
    "\n",
    "        if window_sum >= self.collapse_threshold:\n",
    "            self.done = True\n",
    "            self.done_reason = f\"Collapse: running weight {window_sum:.2f} >= {self.collapse_threshold:.2f}\"\n",
    "            self.raw_score -= 200.0\n",
    "            return self._get_state(), -500.0, True, {\"reason\": self.done_reason}\n",
    "\n",
    "        # alighting\n",
    "        if self.passengers_onboard > 0:\n",
    "            alight = random.randint(0, self.passengers_onboard)\n",
    "            self.passengers_onboard -= alight\n",
    "        at_terminal = (self.station_idx == 0 or self.station_idx == self.num_stations-1)\n",
    "        if at_terminal:\n",
    "            self.passengers_onboard = 0\n",
    "\n",
    "        # arrivals + boarding\n",
    "        arrivals = self._simulate_arrivals()\n",
    "        space = max(0, self.capacity - self.passengers_onboard)\n",
    "        boarded = min(arrivals, space)\n",
    "        self.passengers_onboard += boarded\n",
    "\n",
    "        unused = max(0, self.capacity - self.passengers_onboard)\n",
    "\n",
    "        # === Penalty Growth ===\n",
    "        penalty_growth = 1.0 + (self.steps / 1000)  # penalties double after ~1000 steps\n",
    "\n",
    "        reward_board = 2.0 * boarded\n",
    "        penalty_unused = 0.1 * unused * penalty_growth\n",
    "        station_reward = reward_board - penalty_unused\n",
    "\n",
    "        # trackers\n",
    "        self.raw_score += station_reward\n",
    "        self.total_boarded += boarded\n",
    "        self.total_unused += unused\n",
    "        self.station_visits += 1\n",
    "        self.steps += 1\n",
    "        self.sim_hour = (self.sim_hour + random.randint(0,2)) % 24\n",
    "\n",
    "        hist_row = {\n",
    "            \"step\": self.steps,\n",
    "            \"station_idx\": self.station_idx,\n",
    "            \"station_name\": self.stations[self.station_idx],\n",
    "            \"action\": {0:\"Dagdag\",1:\"Lapad\",2:\"None\"}[action],\n",
    "            \"capacity\": self.capacity,\n",
    "            \"boarded\": boarded,\n",
    "            \"onboard\": self.passengers_onboard,\n",
    "            \"unused\": unused,\n",
    "            \"station_reward\": station_reward,\n",
    "            \"raw_score\": self.raw_score,\n",
    "            \"collapse_threshold\": self.collapse_threshold\n",
    "        }\n",
    "        self.history.append(hist_row)\n",
    "\n",
    "        # move train\n",
    "        next_idx = self.station_idx + self.direction\n",
    "        if next_idx < 0 or next_idx >= self.num_stations:\n",
    "            self.direction *= -1\n",
    "            next_idx = self.station_idx + self.direction\n",
    "        if self.steps >= self.max_steps:\n",
    "            self.done = True\n",
    "            self.done_reason = \"Max steps reached.\"\n",
    "        self.station_idx = next_idx\n",
    "\n",
    "        if self.verbose:\n",
    "            self._print_step(hist_row)\n",
    "\n",
    "        return self._get_state(), station_reward - (0.1 * cost), self.done, {\"history\": hist_row}\n",
    "\n",
    "    def final_score(self, survived_steps):\n",
    "        distance_bonus = survived_steps * 50\n",
    "        effective_score = self.raw_score + distance_bonus\n",
    "        S_min = -50 * self.station_visits\n",
    "        S_max = 200 * self.station_visits\n",
    "        normalized = round(1 + ((effective_score - S_min) / (S_max - S_min)) * 99)\n",
    "        return max(1, min(100, normalized)), effective_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b528c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš† Welcome to Dagdag o Lapad ğŸš†\n",
      "Actions: 0 = Dagdag, 1 = Lapad, 2 = None\n",
      "\n",
      "\n",
      "ğŸš‰------------\n",
      "ğŸš‚\n",
      "ğŸ“ Recto | Cap: 100 | Onboard: 0\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: 153.30 | Onboard: 83\n",
      "\n",
      "\n",
      "-ğŸš‰-----------\n",
      " ğŸš‚\n",
      "ğŸ“ Legarda | Cap: 200 | Onboard: 83\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: -8.83 | Onboard: 22\n",
      "\n",
      "\n",
      "--ğŸš‰----------\n",
      "  ğŸš‚\n",
      "ğŸ“ Pureza | Cap: 300 | Onboard: 22\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 127.06 | Onboard: 91\n",
      "\n",
      "\n",
      "---ğŸš‰---------\n",
      "   ğŸš‚\n",
      "ğŸ“ V. Mapa | Cap: 300 | Onboard: 91\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 168.75 | Onboard: 128\n",
      "\n",
      "\n",
      "----ğŸš‰--------\n",
      "    ğŸš‚\n",
      "ğŸ“ J. Ruiz | Cap: 300 | Onboard: 128\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: 57.71 | Onboard: 113\n",
      "\n",
      "\n",
      "-----ğŸš‰-------\n",
      "     ğŸš‚\n",
      "ğŸ“ Gilmore | Cap: 350 | Onboard: 113\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 0.48 | Onboard: 116\n",
      "\n",
      "\n",
      "------ğŸš‰------\n",
      "      ğŸš‚\n",
      "ğŸ“ Betty Go | Cap: 350 | Onboard: 116\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: 26.59 | Onboard: 53\n",
      "\n",
      "\n",
      "-------ğŸš‰-----\n",
      "       ğŸš‚\n",
      "ğŸ“ Cubao | Cap: 400 | Onboard: 53\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 180.41 | Onboard: 126\n",
      "\n",
      "\n",
      "--------ğŸš‰----\n",
      "        ğŸš‚\n",
      "ğŸ“ Anonas | Cap: 400 | Onboard: 126\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: 25.31 | Onboard: 91\n",
      "\n",
      "\n",
      "---------ğŸš‰---\n",
      "         ğŸš‚\n",
      "ğŸ“ Katipunan | Cap: 450 | Onboard: 91\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -4.98 | Onboard: 24\n",
      "\n",
      "\n",
      "----------ğŸš‰--\n",
      "          ğŸš‚\n",
      "ğŸ“ Santolan | Cap: 450 | Onboard: 24\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: 6.88 | Onboard: 34\n",
      "\n",
      "\n",
      "-----------ğŸš‰-\n",
      "           ğŸš‚\n",
      "ğŸ“ Marikina | Cap: 550 | Onboard: 34\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -35.54 | Onboard: 16\n",
      "\n",
      "\n",
      "------------ğŸš‰\n",
      "            ğŸš‚\n",
      "ğŸ“ Antipolo | Cap: 600 | Onboard: 16\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: 484.98 | Onboard: 0\n",
      "\n",
      "\n",
      "-----------ğŸš‰-\n",
      "           ğŸš‹\n",
      "ğŸ“ Marikina | Cap: 700 | Onboard: 0\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -11.33 | Onboard: 31\n",
      "\n",
      "\n",
      "----------ğŸš‰--\n",
      "          ğŸš‹\n",
      "ğŸ“ Santolan | Cap: 750 | Onboard: 31\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -6.47 | Onboard: 55\n",
      "\n",
      "\n",
      "---------ğŸš‰---\n",
      "         ğŸš‹\n",
      "ğŸ“ Katipunan | Cap: 750 | Onboard: 55\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: 131.47 | Onboard: 110\n",
      "\n",
      "\n",
      "--------ğŸš‰----\n",
      "        ğŸš‹\n",
      "ğŸ“ Anonas | Cap: 800 | Onboard: 110\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 98.98 | Onboard: 101\n",
      "\n",
      "\n",
      "-------ğŸš‰-----\n",
      "       ğŸš‹\n",
      "ğŸ“ Cubao | Cap: 800 | Onboard: 101\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: 156.93 | Onboard: 152\n",
      "\n",
      "\n",
      "------ğŸš‰------\n",
      "      ğŸš‹\n",
      "ğŸ“ Betty Go | Cap: 900 | Onboard: 152\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -61.85 | Onboard: 96\n",
      "\n",
      "\n",
      "-----ğŸš‰-------\n",
      "     ğŸš‹\n",
      "ğŸ“ Gilmore | Cap: 900 | Onboard: 96\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 46.48 | Onboard: 100\n",
      "\n",
      "\n",
      "----ğŸš‰--------\n",
      "    ğŸš‹\n",
      "ğŸ“ J. Ruiz | Cap: 900 | Onboard: 100\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 17.19 | Onboard: 147\n",
      "\n",
      "\n",
      "---ğŸš‰---------\n",
      "   ğŸš‹\n",
      "ğŸ“ V. Mapa | Cap: 900 | Onboard: 147\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -12.73 | Onboard: 125\n",
      "\n",
      "\n",
      "--ğŸš‰----------\n",
      "  ğŸš‹\n",
      "ğŸ“ Pureza | Cap: 950 | Onboard: 125\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -45.09 | Onboard: 137\n",
      "\n",
      "\n",
      "-ğŸš‰-----------\n",
      " ğŸš‹\n",
      "ğŸ“ Legarda | Cap: 950 | Onboard: 137\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: 84.24 | Onboard: 147\n",
      "\n",
      "\n",
      "ğŸš‰------------\n",
      "ğŸš‹\n",
      "ğŸ“ Recto | Cap: 1000 | Onboard: 147\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 343.31 | Onboard: 0\n",
      "\n",
      "\n",
      "-ğŸš‰-----------\n",
      " ğŸš‚\n",
      "ğŸ“ Legarda | Cap: 1000 | Onboard: 0\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: 108.43 | Onboard: 103\n",
      "\n",
      "\n",
      "--ğŸš‰----------\n",
      "  ğŸš‚\n",
      "ğŸ“ Pureza | Cap: 1050 | Onboard: 103\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: 119.12 | Onboard: 157\n",
      "\n",
      "\n",
      "---ğŸš‰---------\n",
      "   ğŸš‚\n",
      "ğŸ“ V. Mapa | Cap: 1150 | Onboard: 157\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: 12.91 | Onboard: 178\n",
      "\n",
      "\n",
      "----ğŸš‰--------\n",
      "    ğŸš‚\n",
      "ğŸ“ J. Ruiz | Cap: 1250 | Onboard: 178\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: 21.27 | Onboard: 111\n",
      "\n",
      "\n",
      "-----ğŸš‰-------\n",
      "     ğŸš‚\n",
      "ğŸ“ Gilmore | Cap: 1300 | Onboard: 111\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: -46.40 | Onboard: 123\n",
      "\n",
      "\n",
      "------ğŸš‰------\n",
      "      ğŸš‚\n",
      "ğŸ“ Betty Go | Cap: 1400 | Onboard: 123\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: -128.29 | Onboard: 70\n",
      "\n",
      "\n",
      "-------ğŸš‰-----\n",
      "       ğŸš‚\n",
      "ğŸ“ Cubao | Cap: 1500 | Onboard: 70\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -49.10 | Onboard: 112\n",
      "\n",
      "\n",
      "--------ğŸš‰----\n",
      "        ğŸš‚\n",
      "ğŸ“ Anonas | Cap: 1500 | Onboard: 112\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: -67.66 | Onboard: 82\n",
      "\n",
      "\n",
      "---------ğŸš‰---\n",
      "         ğŸš‚\n",
      "ğŸ“ Katipunan | Cap: 1600 | Onboard: 82\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -96.50 | Onboard: 85\n",
      "\n",
      "\n",
      "----------ğŸš‰--\n",
      "          ğŸš‚\n",
      "ğŸ“ Santolan | Cap: 1600 | Onboard: 85\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -85.15 | Onboard: 77\n",
      "\n",
      "\n",
      "-----------ğŸš‰-\n",
      "           ğŸš‚\n",
      "ğŸ“ Marikina | Cap: 1650 | Onboard: 77\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -141.24 | Onboard: 31\n",
      "\n",
      "\n",
      "------------ğŸš‰\n",
      "            ğŸš‚\n",
      "ğŸ“ Antipolo | Cap: 1700 | Onboard: 31\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: 39.08 | Onboard: 0\n",
      "\n",
      "\n",
      "-----------ğŸš‰-\n",
      "           ğŸš‹\n",
      "ğŸ“ Marikina | Cap: 1750 | Onboard: 0\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -128.88 | Onboard: 25\n",
      "\n",
      "\n",
      "----------ğŸš‰--\n",
      "          ğŸš‹\n",
      "ğŸ“ Santolan | Cap: 1750 | Onboard: 25\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -34.21 | Onboard: 88\n",
      "\n",
      "\n",
      "---------ğŸš‰---\n",
      "         ğŸš‹\n",
      "ğŸ“ Katipunan | Cap: 1800 | Onboard: 88\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: -93.50 | Onboard: 105\n",
      "\n",
      "\n",
      "--------ğŸš‰----\n",
      "        ğŸš‹\n",
      "ğŸ“ Anonas | Cap: 1900 | Onboard: 105\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -104.16 | Onboard: 110\n",
      "\n",
      "\n",
      "-------ğŸš‰-----\n",
      "       ğŸš‹\n",
      "ğŸ“ Cubao | Cap: 1900 | Onboard: 110\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: 18.12 | Onboard: 128\n",
      "\n",
      "\n",
      "------ğŸš‰------\n",
      "      ğŸš‹\n",
      "ğŸ“ Betty Go | Cap: 2000 | Onboard: 128\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: 16.81 | Onboard: 146\n",
      "\n",
      "\n",
      "-----ğŸš‰-------\n",
      "     ğŸš‹\n",
      "ğŸ“ Gilmore | Cap: 2000 | Onboard: 146\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: -174.04 | Onboard: 115\n",
      "\n",
      "\n",
      "----ğŸš‰--------\n",
      "    ğŸš‹\n",
      "ğŸ“ J. Ruiz | Cap: 2100 | Onboard: 115\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -0.34 | Onboard: 181\n",
      "\n",
      "\n",
      "---ğŸš‰---------\n",
      "   ğŸš‹\n",
      "ğŸ“ V. Mapa | Cap: 2100 | Onboard: 181\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -93.34 | Onboard: 75\n",
      "\n",
      "\n",
      "--ğŸš‰----------\n",
      "  ğŸš‹\n",
      "ğŸ“ Pureza | Cap: 2150 | Onboard: 75\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -143.95 | Onboard: 102\n",
      "\n",
      "\n",
      "-ğŸš‰-----------\n",
      " ğŸš‹\n",
      "ğŸ“ Legarda | Cap: 2200 | Onboard: 102\n",
      "ğŸ² Random Agent chose: 0\n",
      "âœ… Reward: -129.87 | Onboard: 114\n",
      "\n",
      "\n",
      "ğŸš‰------------\n",
      "ğŸš‹\n",
      "ğŸ“ Recto | Cap: 2300 | Onboard: 114\n",
      "ğŸ² Random Agent chose: 1\n",
      "âœ… Reward: -97.34 | Onboard: 0\n",
      "\n",
      "\n",
      "-ğŸš‰-----------\n",
      " ğŸš‚\n",
      "ğŸ“ Legarda | Cap: 2350 | Onboard: 0\n",
      "ğŸ² Random Agent chose: 2\n",
      "âœ… Reward: -183.37 | Onboard: 30\n",
      "\n",
      "\n",
      "============================\n",
      "ğŸ Game Over!\n",
      "ğŸ“Š Raw Score: 2871.64\n",
      "â­ Normalized Score: 44/100\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "# ===============================\n",
    "# TRAIN GAME WITH SCALING + ASCII\n",
    "# ===============================\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class TrainGameEnv:\n",
    "    def __init__(self, initial_capacity=100, seed=None, verbose=False):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # train state\n",
    "        self.initial_capacity = initial_capacity\n",
    "        self.capacity = initial_capacity\n",
    "        self.passengers_onboard = 0\n",
    "\n",
    "        # scoring trackers\n",
    "        self.raw_score = 0.0\n",
    "        self.total_boarded = 0\n",
    "        self.total_unused = 0.0\n",
    "        self.total_config_cost = 0.0\n",
    "\n",
    "        # stations (LRT-2)\n",
    "        self.stations = [\n",
    "            \"Recto\", \"Legarda\", \"Pureza\", \"V. Mapa\", \"J. Ruiz\", \"Gilmore\",\n",
    "            \"Betty Go\", \"Cubao\", \"Anonas\", \"Katipunan\",\n",
    "            \"Santolan\", \"Marikina\", \"Antipolo\"\n",
    "        ]\n",
    "        self.num_stations = len(self.stations)\n",
    "        self.station_idx = 0\n",
    "        self.direction = +1\n",
    "\n",
    "        # collapse mechanic\n",
    "        self.weight_window = []\n",
    "        self.window_size = 10\n",
    "        self.base_collapse_threshold = 10.0\n",
    "\n",
    "        # time + progression\n",
    "        self.sim_hour = random.randint(0, 23)\n",
    "        self.steps = 0\n",
    "        self.max_steps = 2000\n",
    "        self.station_visits = 0\n",
    "\n",
    "        self.done = False\n",
    "        self.done_reason = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # ----------------- helpers -----------------\n",
    "    def _time_multiplier(self, hour):\n",
    "        if 6 <= hour <= 8:   # morning rush\n",
    "            return 1.9\n",
    "        if 11 <= hour <= 13: # lunch rush\n",
    "            return 1.6\n",
    "        if 17 <= hour <= 19: # evening rush\n",
    "            return 1.9\n",
    "        return 0.8 if random.random() < 0.45 else 1.0\n",
    "\n",
    "    def _arrival_bounds(self, idx):\n",
    "        if idx in (0, self.num_stations-1, 7):  # terminals + Cubao\n",
    "            return (40, 150)\n",
    "        return (10, 70)\n",
    "\n",
    "    def _simulate_arrivals(self):\n",
    "        amin, amax = self._arrival_bounds(self.station_idx)\n",
    "        base = random.randint(amin, amax)\n",
    "        mult = self._time_multiplier(self.sim_hour)\n",
    "\n",
    "        # âœ… Passenger Surge Scaling\n",
    "        surge_factor = 1.0 + (self.steps / 2000) * 2.0\n",
    "        return max(0, int(round(base * mult * surge_factor)))\n",
    "\n",
    "    def reset(self):\n",
    "        self.capacity = self.initial_capacity\n",
    "        self.passengers_onboard = 0\n",
    "        self.raw_score = 0.0\n",
    "        self.total_boarded = 0\n",
    "        self.total_unused = 0.0\n",
    "        self.total_config_cost = 0.0\n",
    "        self.station_idx = 0\n",
    "        self.direction = +1\n",
    "        self.weight_window = []\n",
    "        self.sim_hour = random.randint(0,23)\n",
    "        self.steps = 0\n",
    "        self.station_visits = 0\n",
    "        self.done = False\n",
    "        self.done_reason = None\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        return np.array([\n",
    "            float(self.capacity),\n",
    "            float(self.passengers_onboard),\n",
    "            float(self.station_idx),\n",
    "            float(self.direction),\n",
    "            float(self.sim_hour)\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    # ----------------- main step -----------------\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            raise RuntimeError(\"Environment is done. Call reset().\")\n",
    "\n",
    "        # action effects\n",
    "        if action == 0:  # Dagdag\n",
    "            self.capacity += 100\n",
    "            cost = 10.0\n",
    "            weight = 1.0\n",
    "        elif action == 1:  # Lapad\n",
    "            self.capacity += 50\n",
    "            cost = 5.0\n",
    "            weight = 0.5\n",
    "        else:\n",
    "            cost = 0.0\n",
    "            weight = 0.0\n",
    "\n",
    "        # config penalty (small immediate penalty)\n",
    "        config_penalty = 0.5 * cost\n",
    "        self.total_config_cost += cost\n",
    "        self.raw_score -= config_penalty\n",
    "\n",
    "        # âœ… Soft Collapse Pressure\n",
    "        collapse_threshold = max(3.0, self.base_collapse_threshold - (self.steps / 200))\n",
    "        self.weight_window.append(weight)\n",
    "        if len(self.weight_window) > self.window_size:\n",
    "            self.weight_window.pop(0)\n",
    "        if sum(self.weight_window) >= collapse_threshold:\n",
    "            self.done = True\n",
    "            self.done_reason = f\"Collapse at station {self.stations[self.station_idx]}\"\n",
    "            self.raw_score -= 200.0\n",
    "            return self._get_state(), -500.0, True, {\"reason\": self.done_reason}\n",
    "\n",
    "        # random alighting\n",
    "        if self.passengers_onboard > 0:\n",
    "            alight = random.randint(0, self.passengers_onboard)\n",
    "            self.passengers_onboard -= alight\n",
    "\n",
    "        # terminal reset\n",
    "        if self.station_idx in (0, self.num_stations-1):\n",
    "            self.passengers_onboard = 0\n",
    "\n",
    "        # arrivals + boarding\n",
    "        arrivals = self._simulate_arrivals()\n",
    "        space = max(0, self.capacity - self.passengers_onboard)\n",
    "        boarded = min(arrivals, space)\n",
    "        self.passengers_onboard += boarded\n",
    "\n",
    "        unused = max(0, self.capacity - self.passengers_onboard)\n",
    "\n",
    "        # âœ… Penalty Growth\n",
    "        penalty_growth = 1.0 + (self.steps / 1000)\n",
    "        reward_board = 2.0 * boarded\n",
    "        penalty_unused = 0.1 * unused * penalty_growth\n",
    "        station_reward = reward_board - penalty_unused\n",
    "\n",
    "        # update stats\n",
    "        self.raw_score += station_reward\n",
    "        self.total_boarded += boarded\n",
    "        self.total_unused += unused\n",
    "        self.station_visits += 1\n",
    "        self.steps += 1\n",
    "\n",
    "        # advance time\n",
    "        self.sim_hour = (self.sim_hour + random.randint(0,2)) % 24\n",
    "\n",
    "        # station movement\n",
    "        next_idx = self.station_idx + self.direction\n",
    "        if next_idx < 0 or next_idx >= self.num_stations:\n",
    "            self.direction *= -1\n",
    "            next_idx = self.station_idx + self.direction\n",
    "            self.passengers_onboard = 0\n",
    "        self.station_idx = next_idx\n",
    "\n",
    "        # stop if too long\n",
    "        if self.steps >= self.max_steps:\n",
    "            self.done = True\n",
    "            self.done_reason = \"Max steps reached.\"\n",
    "\n",
    "        return self._get_state(), station_reward - (0.1 * cost), self.done, {}\n",
    "\n",
    "    def final_score(self):\n",
    "        distance_bonus = self.station_visits * 50\n",
    "        effective_score = self.raw_score + distance_bonus\n",
    "        S_min = -50 * self.station_visits\n",
    "        S_max = 200 * self.station_visits\n",
    "        normalized = round(1 + ((effective_score - S_min) / (S_max - S_min)) * 99)\n",
    "        return max(1, min(100, normalized)), effective_score\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# ASCII DISPLAY\n",
    "# ===============================\n",
    "def draw_train(env):\n",
    "    track = [\"-\"] * env.num_stations\n",
    "    idx = env.station_idx\n",
    "    track[idx] = \"ğŸš‰\"\n",
    "    train = \"ğŸš‚\" if env.direction == 1 else \"ğŸš‹\"\n",
    "    print(\"\\n\" + \"\".join(track))\n",
    "    print(\" \" * idx + train)\n",
    "    print(f\"ğŸ“ {env.stations[idx]} | Cap: {env.capacity} | Onboard: {env.passengers_onboard}\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# PLAY FUNCTION\n",
    "# ===============================\n",
    "def play_games(auto=True, max_rounds=40, delay=0.3):\n",
    "    env = TrainGameEnv(initial_capacity=100)\n",
    "    print(\"ğŸš† Welcome to Dagdag o Lapad ğŸš†\")\n",
    "    print(\"Actions: 0 = Dagdag, 1 = Lapad, 2 = None\\n\")\n",
    "\n",
    "    for _ in range(max_rounds):\n",
    "        draw_train(env)\n",
    "        if auto:\n",
    "            action = random.choice([0, 1, 2])\n",
    "            print(f\"ğŸ² Random Agent chose: {action}\")\n",
    "        else:\n",
    "            try:\n",
    "                action = int(input(\"Choose [0=Dagdag, 1=Lapad, 2=None]: \"))\n",
    "                if action not in [0,1,2]:\n",
    "                    action = 2\n",
    "            except:\n",
    "                action = 2\n",
    "\n",
    "        _, reward, done, info = env.step(action)\n",
    "        print(f\"âœ… Reward: {reward:.2f} | Onboard: {env.passengers_onboard}\\n\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "        if done:\n",
    "            print(f\"âŒ Game ended: {env.done_reason}\")\n",
    "            break\n",
    "\n",
    "    final_norm, final_raw = env.final_score()\n",
    "    print(\"\\n============================\")\n",
    "    print(\"ğŸ Game Over!\")\n",
    "    print(f\"ğŸ“Š Raw Score: {final_raw:.2f}\")\n",
    "    print(f\"â­ Normalized Score: {final_norm}/100\")\n",
    "    print(\"============================\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# RUN SHOWCASE\n",
    "# ===============================\n",
    "play_game(auto=True, max_rounds=50, delay=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1669a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# AGENT IMPLEMENTATION\n",
    "# ===============================\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# For Actor-Critic\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ---- state discretizer for tabular agents ----\n",
    "def discretize_state(state):\n",
    "    # state: [capacity, onboard, station_idx, direction, sim_hour]\n",
    "    cap, onboard, station_idx, direction, sim_hour = state\n",
    "    cap_bin = int(cap // 100)    # bucket by 100s\n",
    "    on_bin = int(onboard // 50)  # bucket by 50s\n",
    "    dir_bin = 1 if direction >= 0 else 0\n",
    "    hour_seg = int(sim_hour // 4)  # 0..5\n",
    "    return (cap_bin, on_bin, int(station_idx), dir_bin, hour_seg)\n",
    "\n",
    "# ---- Monte Carlo Agent ----\n",
    "class MonteCarloAgent:\n",
    "    def __init__(self, n_actions=3, eps=0.1):\n",
    "        self.n_actions = n_actions\n",
    "        self.eps = eps\n",
    "        self.Q = defaultdict(float)\n",
    "        self.returns = defaultdict(list)\n",
    "\n",
    "    def policy(self, state, greedy=False):\n",
    "        ds = discretize_state(state)\n",
    "        if (not greedy) and (random.random() < self.eps):\n",
    "            return random.randint(0, self.n_actions-1)\n",
    "        qvals = [self.Q[(ds,a)] for a in range(self.n_actions)]\n",
    "        return int(np.argmax(qvals))\n",
    "\n",
    "    def update(self, episode):  # list of (state, action, reward)\n",
    "        G = 0\n",
    "        visited = set()\n",
    "        for s,a,r in reversed(episode):\n",
    "            G = r + G\n",
    "            key = (tuple(discretize_state(s)), a)\n",
    "            if key not in visited:\n",
    "                visited.add(key)\n",
    "                self.returns[key].append(G)\n",
    "                self.Q[key] = np.mean(self.returns[key])\n",
    "\n",
    "# ---- Q-Learning Agent ----\n",
    "class QLearningAgent:\n",
    "    def __init__(self, n_actions=3, alpha=0.1, gamma=0.99, eps=0.1):\n",
    "        self.n_actions = n_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.Q = defaultdict(float)\n",
    "\n",
    "    def policy(self, state, greedy=False):\n",
    "        ds = discretize_state(state)\n",
    "        if (not greedy) and (random.random() < self.eps):\n",
    "            return random.randint(0, self.n_actions-1)\n",
    "        qvals = [self.Q[(ds,a)] for a in range(self.n_actions)]\n",
    "        return int(np.argmax(qvals))\n",
    "\n",
    "    def update(self, s, a, r, s_next):\n",
    "        ds = discretize_state(s)\n",
    "        ds_next = discretize_state(s_next)\n",
    "        best_next = max([self.Q[(ds_next, a2)] for a2 in range(self.n_actions)])\n",
    "        self.Q[(ds,a)] += self.alpha * (r + self.gamma * best_next - self.Q[(ds,a)])\n",
    "\n",
    "# ---- Actor-Critic Agent ----\n",
    "class ACNetwork(nn.Module):\n",
    "    def __init__(self, state_dim=5, action_dim=3, hidden=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden)\n",
    "        self.actor = nn.Linear(hidden, action_dim)\n",
    "        self.critic = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        policy = torch.softmax(self.actor(x), dim=-1)\n",
    "        value = self.critic(x)\n",
    "        return policy, value\n",
    "\n",
    "class ActorCriticAgent:\n",
    "    def __init__(self, state_dim=5, action_dim=3, lr=1e-3, gamma=0.99):\n",
    "        self.net = ACNetwork(state_dim, action_dim)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=lr)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def policy(self, state):\n",
    "        st = torch.FloatTensor(state).unsqueeze(0)  # batchify\n",
    "        probs, val = self.net(st)\n",
    "        dist = torch.distributions.Categorical(probs)\n",
    "        a = dist.sample()\n",
    "        return a.item(), dist.log_prob(a), val\n",
    "\n",
    "    def learn(self, trajectory):\n",
    "        returns = []\n",
    "        G = 0\n",
    "        for _,_,r,_ in reversed(trajectory):\n",
    "            G = r + self.gamma * G\n",
    "            returns.insert(0, G)\n",
    "        returns = torch.tensor(returns, dtype=torch.float32)\n",
    "        log_probs = torch.stack([t[1] for t in trajectory])\n",
    "        values = torch.cat([t[3] for t in trajectory]).squeeze()\n",
    "        advantages = returns - values.detach()\n",
    "        actor_loss = -(log_probs * advantages).mean()\n",
    "        critic_loss = nn.MSELoss()(values, returns)\n",
    "        loss = actor_loss + critic_loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# AGENT TRAINING\n",
    "# ===============================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_policy_agent(agent, env_ctor, episodes=10):\n",
    "    scores = []\n",
    "    for _ in range(episodes):\n",
    "        env = env_ctor()\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            if isinstance(agent, ActorCriticAgent):\n",
    "                a,_,_ = agent.policy(s)\n",
    "            else:\n",
    "                a = agent.policy(s, greedy=True)\n",
    "            s, r, done, _ = env.step(a)\n",
    "        norm, raw = env.final_score()\n",
    "        scores.append(norm)\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "def train_mc(agent, env_ctor, episodes=300, max_steps_per_ep=200):\n",
    "    eval_every = max(10, episodes//20)\n",
    "    eval_scores = []\n",
    "    for ep in range(episodes):\n",
    "        env = env_ctor()\n",
    "        state = env.reset()\n",
    "        episode = []\n",
    "        done = False\n",
    "        steps = 0\n",
    "        while not done and steps < max_steps_per_ep:\n",
    "            a = agent.policy(state)\n",
    "            next_state, reward, done, _ = env.step(a)\n",
    "            episode.append((state, a, reward))\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "        agent.update(episode)\n",
    "        if (ep+1) % eval_every == 0 or ep==episodes-1:\n",
    "            mean_score, _ = evaluate_policy_agent(agent, env_ctor, episodes=6)\n",
    "            eval_scores.append((ep+1, mean_score))\n",
    "    return eval_scores\n",
    "\n",
    "def train_q(agent, env_ctor, episodes=300, max_steps_per_ep=200):\n",
    "    eval_every = max(10, episodes//20)\n",
    "    eval_scores = []\n",
    "    for ep in range(episodes):\n",
    "        env = env_ctor()\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        while not done and steps < max_steps_per_ep:\n",
    "            a = agent.policy(s)\n",
    "            s_next, r, done, _ = env.step(a)\n",
    "            agent.update(s, a, r, s_next)\n",
    "            s = s_next\n",
    "            steps += 1\n",
    "        if (ep+1) % eval_every == 0 or ep==episodes-1:\n",
    "            mean_score, _ = evaluate_policy_agent(agent, env_ctor, episodes=6)\n",
    "            eval_scores.append((ep+1, mean_score))\n",
    "    return eval_scores\n",
    "\n",
    "def train_ac(agent, env_ctor, episodes=300, max_steps_per_ep=200):\n",
    "    eval_every = max(10, episodes//20)\n",
    "    eval_scores = []\n",
    "    for ep in range(episodes):\n",
    "        env = env_ctor()\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        trajectory = []\n",
    "        while not done and steps < max_steps_per_ep:\n",
    "            a, logprob, val = agent.policy(s)\n",
    "            s_next, r, done, _ = env.step(a)\n",
    "            trajectory.append((s, logprob, r, val))\n",
    "            s = s_next\n",
    "            steps += 1\n",
    "        if len(trajectory) > 0:\n",
    "            agent.learn(trajectory)\n",
    "        if (ep+1) % eval_every == 0 or ep==episodes-1:\n",
    "            mean_score, _ = evaluate_policy_agent(agent, env_ctor, episodes=6)\n",
    "            eval_scores.append((ep+1, mean_score))\n",
    "    return eval_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a31815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Monte Carlo...\n",
      "Training Q-Learning...\n",
      "Training Actor-Critic...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Playthrough â€” Monte Carlo (trained)\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 1 | Action 0 | Reward 260.4 | raw_score 256.4\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 2 | Action 1 | Reward 104.6 | raw_score 359.0\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 3 | Action 2 | Reward 93.4 | raw_score 452.4\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 4 | Action 2 | Reward 134.4 | raw_score 586.7\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 5 | Action 1 | Reward 189.1 | raw_score 773.8\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 6 | Action 1 | Reward 57.7 | raw_score 829.5\n",
      "Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â· | Step 7 | Action 1 | Reward 135.1 | raw_score 962.7\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â· | Step 8 | Action 2 | Reward 227.4 | raw_score 1190.1\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â· | Step 9 | Action 1 | Reward 31.3 | raw_score 1219.4\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â· | Step 10 | Action 1 | Reward 10.5 | raw_score 1227.8\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â· | Step 11 | Action 0 | Reward 65.5 | raw_score 1289.4\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚ | Step 12 | Action 1 | Reward 19.1 | raw_score 1306.5\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â· | Step 13 | Action 1 | Reward 155.6 | raw_score 1460.1\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â· | Step 14 | Action 2 | Reward 204.4 | raw_score 1664.5\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â· | Step 15 | Action 2 | Reward 86.9 | raw_score 1751.4\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â· | Step 16 | Action 2 | Reward -29.5 | raw_score 1721.9\n",
      "Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â· | Step 17 | Action 0 | Reward 10.2 | raw_score 1728.1\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 18 | Action 0 | Reward 157.8 | raw_score 1882.0\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 19 | Action 0 | Reward 0.2 | raw_score 1878.2\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 20 | Action 0 | Reward -79.2 | raw_score 1795.0\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 21 | Action 0 | Reward 21.9 | raw_score 1812.9\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 22 | Action 2 | Reward -85.7 | raw_score 1727.1\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 23 | Action 0 | Reward -89.5 | raw_score 1633.6\n",
      "ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 24 | Action 2 | Reward -40.4 | raw_score 1593.2\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 25 | Action 0 | Reward 68.0 | raw_score 1657.2\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 26 | Action 1 | Reward 80.0 | raw_score 1735.3\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 27 | Action 2 | Reward 82.0 | raw_score 1817.2\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 28 | Action 0 | Reward 23.3 | raw_score 1836.5\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 29 | Action 2 | Reward 1.6 | raw_score 1838.1\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 30 | Action 1 | Reward -18.2 | raw_score 1817.9\n",
      "Result Monte Carlo (trained): normalized=65/100 raw=3317.90 reason=None\n",
      "\n",
      "========================================\n",
      "Playthrough â€” Q-Learning (trained)\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 1 | Action 0 | Reward 201.6 | raw_score 197.6\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 2 | Action 0 | Reward 180.3 | raw_score 373.9\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 3 | Action 0 | Reward 9.2 | raw_score 379.1\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 4 | Action 1 | Reward 74.1 | raw_score 451.2\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 5 | Action 1 | Reward 29.3 | raw_score 478.5\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 6 | Action 0 | Reward 170.9 | raw_score 645.4\n",
      "Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â· | Step 7 | Action 2 | Reward 153.2 | raw_score 798.6\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â· | Step 8 | Action 0 | Reward 241.2 | raw_score 1035.8\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â· | Step 9 | Action 0 | Reward -1.6 | raw_score 1030.2\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â· | Step 10 | Action 0 | Reward 163.9 | raw_score 1190.1\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â· | Step 11 | Action 2 | Reward -29.2 | raw_score 1160.9\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚ | Step 12 | Action 2 | Reward -34.0 | raw_score 1126.9\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â· | Step 13 | Action 2 | Reward 228.3 | raw_score 1355.2\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â· | Step 14 | Action 0 | Reward 4.9 | raw_score 1356.1\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â· | Step 15 | Action 1 | Reward -37.5 | raw_score 1316.6\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â· | Step 16 | Action 1 | Reward 140.0 | raw_score 1454.6\n",
      "Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â· | Step 17 | Action 1 | Reward -74.1 | raw_score 1378.4\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 18 | Action 1 | Reward 119.7 | raw_score 1496.2\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 19 | Action 1 | Reward -91.8 | raw_score 1402.4\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 20 | Action 2 | Reward 54.0 | raw_score 1456.4\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 21 | Action 0 | Reward 6.4 | raw_score 1458.8\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 22 | Action 1 | Reward 100.4 | raw_score 1557.2\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 23 | Action 0 | Reward 20.0 | raw_score 1573.2\n",
      "ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 24 | Action 2 | Reward -10.9 | raw_score 1562.3\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 25 | Action 0 | Reward 354.5 | raw_score 1912.7\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 26 | Action 2 | Reward -111.4 | raw_score 1801.3\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 27 | Action 1 | Reward -42.1 | raw_score 1757.2\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 28 | Action 0 | Reward -83.4 | raw_score 1669.8\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 29 | Action 2 | Reward -127.6 | raw_score 1542.1\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 30 | Action 2 | Reward -122.2 | raw_score 1420.0\n",
      "Result Q-Learning (trained): normalized=59/100 raw=2919.99 reason=None\n",
      "\n",
      "========================================\n",
      "Playthrough â€” Actor-Critic (trained)\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 1 | Action 2 | Reward 200.0 | raw_score 200.0\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 2 | Action 2 | Reward 76.0 | raw_score 276.0\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 3 | Action 2 | Reward 33.1 | raw_score 309.1\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 4 | Action 2 | Reward 89.8 | raw_score 398.9\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 5 | Action 2 | Reward 94.0 | raw_score 492.9\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 6 | Action 2 | Reward 44.8 | raw_score 537.7\n",
      "Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â· | Step 7 | Action 2 | Reward 82.4 | raw_score 620.1\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â· | Step 8 | Action 2 | Reward 173.8 | raw_score 793.9\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â· | Step 9 | Action 2 | Reward 62.0 | raw_score 855.9\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â· | Step 10 | Action 2 | Reward 2.0 | raw_score 857.9\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â· | Step 11 | Action 2 | Reward 49.9 | raw_score 907.8\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚ | Step 12 | Action 2 | Reward 61.9 | raw_score 969.7\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â· | Step 13 | Action 2 | Reward 200.0 | raw_score 1169.7\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â· | Step 14 | Action 2 | Reward 82.3 | raw_score 1252.1\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â· | Step 15 | Action 2 | Reward 135.3 | raw_score 1387.3\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â· | Step 16 | Action 2 | Reward 83.3 | raw_score 1470.6\n",
      "Â·Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â· | Step 17 | Action 2 | Reward 42.6 | raw_score 1513.3\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 18 | Action 2 | Reward 136.0 | raw_score 1649.3\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 19 | Action 2 | Reward 88.0 | raw_score 1737.3\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 20 | Action 2 | Reward 41.0 | raw_score 1778.3\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 21 | Action 2 | Reward 169.3 | raw_score 1947.5\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 22 | Action 2 | Reward 60.0 | raw_score 2007.5\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 23 | Action 2 | Reward 8.0 | raw_score 2015.5\n",
      "ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 24 | Action 2 | Reward 22.0 | raw_score 2037.5\n",
      "Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 25 | Action 2 | Reward 200.0 | raw_score 2237.5\n",
      "Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 26 | Action 2 | Reward 200.0 | raw_score 2437.5\n",
      "Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â·Â· | Step 27 | Action 2 | Reward 58.5 | raw_score 2496.1\n",
      "Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â·Â· | Step 28 | Action 2 | Reward 42.0 | raw_score 2538.1\n",
      "Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â·Â· | Step 29 | Action 2 | Reward 26.3 | raw_score 2564.4\n",
      "Â·Â·Â·Â·Â·Â·ğŸš‚Â·Â·Â·Â·Â·Â· | Step 30 | Action 2 | Reward 39.4 | raw_score 2603.8\n",
      "Result Actor-Critic (trained): normalized=75/100 raw=4103.78 reason=None\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# AGENT TEST RUN (cleaned + fixed)\n",
    "# ===============================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "# Environment constructor for fresh envs\n",
    "def env_ctor():\n",
    "    # Always create new env, difficulty scaling is inside TrainGameEnv\n",
    "    return TrainGameEnv(seed=None, verbose=False)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Instantiate agents\n",
    "mc_agent = MonteCarloAgent(n_actions=3, eps=0.1)\n",
    "q_agent = QLearningAgent(n_actions=3, alpha=0.1, gamma=0.99, eps=0.1)\n",
    "ac_agent = ActorCriticAgent(state_dim=5, action_dim=3, lr=1e-3, gamma=0.99)\n",
    "\n",
    "# Training parameters\n",
    "EPISODES = 1000\n",
    "\n",
    "print(\"Training Monte Carlo...\")\n",
    "mc_scores = train_mc(mc_agent, env_ctor, episodes=EPISODES)\n",
    "print(\"Training Q-Learning...\")\n",
    "q_scores = train_q(q_agent, env_ctor, episodes=EPISODES)\n",
    "print(\"Training Actor-Critic...\")\n",
    "ac_scores = train_ac(ac_agent, env_ctor, episodes=EPISODES)\n",
    "\n",
    "# Convert training logs to X/Y for plotting\n",
    "def to_xy(score_list):\n",
    "    xs = [x for x, _ in score_list]\n",
    "    ys = [y for _, y in score_list]\n",
    "    return xs, ys\n",
    "\n",
    "mc_x, mc_y = to_xy(mc_scores)\n",
    "q_x, q_y = to_xy(q_scores)\n",
    "ac_x, ac_y = to_xy(ac_scores)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(mc_x, mc_y, label=\"Monte Carlo\")\n",
    "plt.plot(q_x, q_y, label=\"Q-Learning\")\n",
    "plt.plot(ac_x, ac_y, label=\"Actor-Critic\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Eval average normalized score (1â€“100)\")\n",
    "plt.title(\"Learning curves (evaluated periodically)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation playthroughs\n",
    "def rollout_and_print(agent, title, max_steps=30):\n",
    "    env = env_ctor()\n",
    "    state = env.reset()\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Playthrough â€” {title}\")\n",
    "    steps = 0\n",
    "\n",
    "    while (not env.done) and steps < max_steps:\n",
    "        if isinstance(agent, ActorCriticAgent):\n",
    "            action, _, _ = agent.policy(state)\n",
    "        else:\n",
    "            action = agent.policy(state, greedy=True)\n",
    "\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        # ASCII track\n",
    "        line = [\"Â·\"] * env.num_stations\n",
    "        if 0 <= env.station_idx < len(line):\n",
    "            line[env.station_idx] = \"ğŸš‚\"\n",
    "        print(\"\".join(line), f\"| Step {steps+1} | Action {action} | Reward {reward:.1f} | raw_score {env.raw_score:.1f}\")\n",
    "\n",
    "        steps += 1\n",
    "        time.sleep(0.04)\n",
    "\n",
    "    norm, raw = env.final_score()  # no steps arg anymore\n",
    "    print(f\"Result {title}: normalized={norm}/100 raw={raw:.2f} reason={env.done_reason}\")\n",
    "\n",
    "# Show each trained agent\n",
    "rollout_and_print(mc_agent, \"Monte Carlo (trained)\")\n",
    "rollout_and_print(q_agent, \"Q-Learning (trained)\")\n",
    "rollout_and_print(ac_agent, \"Actor-Critic (trained)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš† Welcome to Dagdag o Lapad â€” User Mode ğŸš†\n",
      "Actions: 0 = Dagdag (+100 cap), 1 = Lapad (+50 cap), 2 = None (no change)\n",
      "\n",
      "\n",
      "=== Round 1 ===\n",
      "ğŸ“ Station: Recto\n",
      "ğŸš‹ Capacity: 100 | Onboard: 0\n",
      "ğŸ•’ Hour: 3 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 285.60 | Onboard after step: 146\n",
      "\n",
      "=== Round 2 ===\n",
      "ğŸ“ Station: Legarda\n",
      "ğŸš‹ Capacity: 200 | Onboard: 146\n",
      "ğŸ•’ Hour: 5 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 40.98 | Onboard after step: 60\n",
      "\n",
      "=== Round 3 ===\n",
      "ğŸ“ Station: Pureza\n",
      "ğŸš‹ Capacity: 300 | Onboard: 60\n",
      "ğŸ•’ Hour: 5 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 20.95 | Onboard after step: 30\n",
      "\n",
      "=== Round 4 ===\n",
      "ğŸ“ Station: V. Mapa\n",
      "ğŸš‹ Capacity: 300 | Onboard: 30\n",
      "ğŸ•’ Hour: 5 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: -6.89 | Onboard after step: 12\n",
      "\n",
      "=== Round 5 ===\n",
      "ğŸ“ Station: J. Ruiz\n",
      "ğŸš‹ Capacity: 300 | Onboard: 12\n",
      "ğŸ•’ Hour: 7 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 163.28 | Onboard after step: 104\n",
      "\n",
      "=== Round 6 ===\n",
      "ğŸ“ Station: Gilmore\n",
      "ğŸš‹ Capacity: 400 | Onboard: 104\n",
      "ğŸ•’ Hour: 7 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 112.15 | Onboard after step: 103\n",
      "\n",
      "=== Round 7 ===\n",
      "ğŸ“ Station: Betty Go\n",
      "ğŸš‹ Capacity: 400 | Onboard: 103\n",
      "ğŸ•’ Hour: 8 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 153.37 | Onboard after step: 175\n",
      "\n",
      "=== Round 8 ===\n",
      "ğŸ“ Station: Cubao\n",
      "ğŸš‹ Capacity: 400 | Onboard: 175\n",
      "ğŸ•’ Hour: 10 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 112.83 | Onboard after step: 150\n",
      "\n",
      "=== Round 9 ===\n",
      "ğŸ“ Station: Anonas\n",
      "ğŸš‹ Capacity: 400 | Onboard: 150\n",
      "ğŸ•’ Hour: 12 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 2.67 | Onboard after step: 109\n",
      "\n",
      "=== Round 10 ===\n",
      "ğŸ“ Station: Katipunan\n",
      "ğŸš‹ Capacity: 400 | Onboard: 109\n",
      "ğŸ•’ Hour: 14 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: -16.10 | Onboard after step: 62\n",
      "\n",
      "=== Round 11 ===\n",
      "ğŸ“ Station: Santolan\n",
      "ğŸš‹ Capacity: 400 | Onboard: 62\n",
      "ğŸ•’ Hour: 14 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 48.77 | Onboard after step: 71\n",
      "\n",
      "=== Round 12 ===\n",
      "ğŸ“ Station: Marikina\n",
      "ğŸš‹ Capacity: 400 | Onboard: 71\n",
      "ğŸ•’ Hour: 14 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 21.55 | Onboard after step: 79\n",
      "\n",
      "=== Round 13 ===\n",
      "ğŸ“ Station: Antipolo\n",
      "ğŸš‹ Capacity: 400 | Onboard: 79\n",
      "ğŸ•’ Hour: 15 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 188.55 | Onboard after step: 0\n",
      "\n",
      "=== Round 14 ===\n",
      "ğŸ“ Station: Marikina\n",
      "ğŸš‹ Capacity: 400 | Onboard: 0\n",
      "ğŸ•’ Hour: 15 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 79.25 | Onboard after step: 57\n",
      "\n",
      "=== Round 15 ===\n",
      "ğŸ“ Station: Santolan\n",
      "ğŸš‹ Capacity: 400 | Onboard: 57\n",
      "ğŸ•’ Hour: 16 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 58.06 | Onboard after step: 85\n",
      "\n",
      "=== Round 16 ===\n",
      "ğŸ“ Station: Katipunan\n",
      "ğŸš‹ Capacity: 400 | Onboard: 85\n",
      "ğŸ•’ Hour: 17 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 237.64 | Onboard after step: 160\n",
      "\n",
      "=== Round 17 ===\n",
      "ğŸ“ Station: Anonas\n",
      "ğŸš‹ Capacity: 400 | Onboard: 160\n",
      "ğŸ•’ Hour: 17 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 89.28 | Onboard after step: 137\n",
      "\n",
      "=== Round 18 ===\n",
      "ğŸ“ Station: Cubao\n",
      "ğŸš‹ Capacity: 400 | Onboard: 137\n",
      "ğŸ•’ Hour: 19 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 142.98 | Onboard after step: 95\n",
      "\n",
      "=== Round 19 ===\n",
      "ğŸ“ Station: Betty Go\n",
      "ğŸš‹ Capacity: 400 | Onboard: 95\n",
      "ğŸ•’ Hour: 20 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 85.74 | Onboard after step: 142\n",
      "\n",
      "=== Round 20 ===\n",
      "ğŸ“ Station: Gilmore\n",
      "ğŸš‹ Capacity: 400 | Onboard: 142\n",
      "ğŸ•’ Hour: 21 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 72.09 | Onboard after step: 185\n",
      "\n",
      "=== Round 21 ===\n",
      "ğŸ“ Station: J. Ruiz\n",
      "ğŸš‹ Capacity: 400 | Onboard: 185\n",
      "ğŸ•’ Hour: 22 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 66.25 | Onboard after step: 226\n",
      "\n",
      "=== Round 22 ===\n",
      "ğŸ“ Station: V. Mapa\n",
      "ğŸš‹ Capacity: 400 | Onboard: 226\n",
      "ğŸ•’ Hour: 22 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 62.15 | Onboard after step: 186\n",
      "\n",
      "=== Round 23 ===\n",
      "ğŸ“ Station: Pureza\n",
      "ğŸš‹ Capacity: 400 | Onboard: 186\n",
      "ğŸ•’ Hour: 23 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 73.44 | Onboard after step: 101\n",
      "\n",
      "=== Round 24 ===\n",
      "ğŸ“ Station: Legarda\n",
      "ğŸš‹ Capacity: 400 | Onboard: 101\n",
      "ğŸ•’ Hour: 1 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 96.64 | Onboard after step: 113\n",
      "\n",
      "=== Round 25 ===\n",
      "ğŸ“ Station: Recto\n",
      "ğŸš‹ Capacity: 400 | Onboard: 113\n",
      "ğŸ•’ Hour: 3 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 208.50 | Onboard after step: 0\n",
      "\n",
      "=== Round 26 ===\n",
      "ğŸ“ Station: Legarda\n",
      "ğŸš‹ Capacity: 500 | Onboard: 0\n",
      "ğŸ•’ Hour: 4 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 32.11 | Onboard after step: 45\n",
      "\n",
      "=== Round 27 ===\n",
      "ğŸ“ Station: Pureza\n",
      "ğŸš‹ Capacity: 600 | Onboard: 45\n",
      "ğŸ•’ Hour: 5 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 47.54 | Onboard after step: 62\n",
      "\n",
      "=== Round 28 ===\n",
      "ğŸ“ Station: V. Mapa\n",
      "ğŸš‹ Capacity: 700 | Onboard: 62\n",
      "ğŸ•’ Hour: 5 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 14.75 | Onboard after step: 77\n",
      "\n",
      "=== Round 29 ===\n",
      "ğŸ“ Station: J. Ruiz\n",
      "ğŸš‹ Capacity: 800 | Onboard: 77\n",
      "ğŸ•’ Hour: 7 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 103.03 | Onboard after step: 161\n",
      "\n",
      "=== Round 30 ===\n",
      "ğŸ“ Station: Gilmore\n",
      "ğŸš‹ Capacity: 900 | Onboard: 161\n",
      "ğŸ•’ Hour: 7 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "Invalid input. Defaulting to 2 (None).\n",
      "âœ… Reward: 95.26 | Onboard after step: 232\n",
      "\n",
      "=== Round 31 ===\n",
      "ğŸ“ Station: Betty Go\n",
      "ğŸš‹ Capacity: 900 | Onboard: 232\n",
      "ğŸ•’ Hour: 7 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: -30.72 | Onboard after step: 226\n",
      "\n",
      "=== Round 32 ===\n",
      "ğŸ“ Station: Cubao\n",
      "ğŸš‹ Capacity: 1000 | Onboard: 226\n",
      "ğŸ•’ Hour: 8 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 172.15 | Onboard after step: 277\n",
      "\n",
      "=== Round 33 ===\n",
      "ğŸ“ Station: Anonas\n",
      "ğŸš‹ Capacity: 1100 | Onboard: 277\n",
      "ğŸ•’ Hour: 8 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 85.73 | Onboard after step: 335\n",
      "\n",
      "=== Round 34 ===\n",
      "ğŸ“ Station: Katipunan\n",
      "ğŸš‹ Capacity: 1200 | Onboard: 335\n",
      "ğŸ•’ Hour: 10 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: -26.05 | Onboard after step: 225\n",
      "\n",
      "=== Round 35 ===\n",
      "ğŸ“ Station: Santolan\n",
      "ğŸš‹ Capacity: 1300 | Onboard: 225\n",
      "ğŸ•’ Hour: 10 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: -10.49 | Onboard after step: 109\n",
      "\n",
      "=== Round 36 ===\n",
      "ğŸ“ Station: Marikina\n",
      "ğŸš‹ Capacity: 1400 | Onboard: 109\n",
      "ğŸ•’ Hour: 10 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: -118.04 | Onboard after step: 60\n",
      "\n",
      "=== Round 37 ===\n",
      "ğŸ“ Station: Antipolo\n",
      "ğŸš‹ Capacity: 1500 | Onboard: 60\n",
      "ğŸ•’ Hour: 11 | Direction: Eastbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: 39.39 | Onboard after step: 0\n",
      "\n",
      "=== Round 38 ===\n",
      "ğŸ“ Station: Marikina\n",
      "ğŸš‹ Capacity: 1600 | Onboard: 0\n",
      "ğŸ•’ Hour: 12 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: -19.51 | Onboard after step: 75\n",
      "\n",
      "=== Round 39 ===\n",
      "ğŸ“ Station: Santolan\n",
      "ğŸš‹ Capacity: 1700 | Onboard: 75\n",
      "ğŸ•’ Hour: 14 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: -134.81 | Onboard after step: 87\n",
      "\n",
      "=== Round 40 ===\n",
      "ğŸ“ Station: Katipunan\n",
      "ğŸš‹ Capacity: 1800 | Onboard: 87\n",
      "ğŸ•’ Hour: 14 | Direction: Westbound\n",
      "âš–ï¸  Collapse Threshold: 10.00\n",
      "Choose your action:\n",
      "  0 = Dagdag (+100 cap)\n",
      "  1 = Lapad  (+50 cap)\n",
      "  2 = None   (no change)\n",
      "âœ… Reward: -500.00 | Onboard after step: 87\n",
      "\n",
      "âŒ Game ended: Collapse at station Katipunan\n",
      "\n",
      "============================\n",
      "ğŸ Game Over!\n",
      "ğŸ“Š Raw Score: 4327.06\n",
      "â­ Normalized Score: 65/100\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "def play_game_user(max_rounds=40, delay=0.2):\n",
    "    \"\"\"\n",
    "    Play TrainGameEnv interactively as a human user.\n",
    "    \"\"\"\n",
    "    env = TrainGameEnv(initial_capacity=100)\n",
    "    print(\"ğŸš† Welcome to Dagdag o Lapad â€” User Mode ğŸš†\")\n",
    "    print(\"Actions: 0 = Dagdag (+100 cap), 1 = Lapad (+50 cap), 2 = None (no change)\\n\")\n",
    "\n",
    "    for round_num in range(1, max_rounds+1):\n",
    "        # Display current state\n",
    "        print(f\"\\n=== Round {round_num} ===\")\n",
    "        print(f\"ğŸ“ Station: {env.stations[env.station_idx]}\")\n",
    "        print(f\"ğŸš‹ Capacity: {env.capacity} | Onboard: {env.passengers_onboard}\")\n",
    "        print(f\"ğŸ•’ Hour: {env.sim_hour} | Direction: {'Eastbound' if env.direction==1 else 'Westbound'}\")\n",
    "        print(f\"âš–ï¸  Collapse Threshold: {getattr(env, 'collapse_thres00000hold', getattr(env, 'base_collapse_threshold', 10.0)):.2f}\")\n",
    "        print(\"Choose your action:\")\n",
    "        print(\"  0 = Dagdag (+100 cap)\")\n",
    "        print(\"  1 = Lapad  (+50 cap)\")\n",
    "        print(\"  2 = None   (no change)\")\n",
    "\n",
    "        # Get user input\n",
    "        try:\n",
    "            action = int(input(\"Enter action [0/1/2]: \"))\n",
    "            if action not in [0, 1, 2]:\n",
    "                print(\"Invalid input. Defaulting to 2 (None).\")\n",
    "                action = 2\n",
    "        except Exception:\n",
    "            print(\"Invalid input. Defaulting to 2 (None).\")\n",
    "            action = 2\n",
    "\n",
    "        # Step environment\n",
    "        _, reward, done, info = env.step(action)\n",
    "        print(f\"âœ… Reward: {reward:.2f} | Onboard after step: {env.passengers_onboard}\")\n",
    "\n",
    "        if done:\n",
    "            print(f\"\\nâŒ Game ended: {env.done_reason}\")\n",
    "            break\n",
    "\n",
    "        import time\n",
    "        time.sleep(delay)\n",
    "\n",
    "    # Show final score\n",
    "    try:\n",
    "        final_norm, final_raw = env.final_score()\n",
    "    except TypeError:\n",
    "        # Some envs require survived_steps, fallback to station_visits\n",
    "        final_norm, final_raw = env.final_score(getattr(env, \"station_visits\", 0))\n",
    "    print(\"\\n============================\")\n",
    "    print(\"ğŸ Game Over!\")\n",
    "    print(f\"ğŸ“Š Raw Score: {final_raw:.2f}\")\n",
    "    print(f\"â­ Normalized Score: {final_norm}/100\")\n",
    "    print(\"============================\")\n",
    "    \n",
    "play_game_user(max_rounds=40, delay=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
